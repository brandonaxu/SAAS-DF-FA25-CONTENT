{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Data Manipulation and Exploratory Data Analysis\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will be able to:\n",
    "- Master advanced Pandas operations for data manipulation\n",
    "- Perform comprehensive exploratory data analysis (EDA)\n",
    "- Handle missing data and outliers effectively\n",
    "- Create meaningful visualizations with Matplotlib and Seaborn\n",
    "- Apply data cleaning techniques to real datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "Let's start by importing our libraries and creating a realistic dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic customer dataset\n",
    "np.random.seed(42)\n",
    "n_customers = 1000\n",
    "\n",
    "# Generate synthetic customer data with realistic relationships\n",
    "ages = np.random.normal(35, 12, n_customers)\n",
    "ages = np.clip(ages, 18, 80).astype(int)\n",
    "\n",
    "# Income correlated with age\n",
    "base_income = 30000 + (ages - 18) * 1200 + np.random.normal(0, 15000, n_customers)\n",
    "income = np.clip(base_income, 20000, 150000)\n",
    "\n",
    "# Purchase behavior\n",
    "purchase_frequency = np.random.poisson(8, n_customers)\n",
    "avg_purchase_amount = 50 + (income / 1000) * 0.5 + np.random.normal(0, 20, n_customers)\n",
    "avg_purchase_amount = np.clip(avg_purchase_amount, 10, 500)\n",
    "\n",
    "# Customer satisfaction\n",
    "satisfaction = 3 + (income / 50000) + (avg_purchase_amount / 100) + np.random.normal(0, 0.8, n_customers)\n",
    "satisfaction = np.clip(satisfaction, 1, 5)\n",
    "\n",
    "# Categories and regions\n",
    "categories = ['Electronics', 'Clothing', 'Books', 'Home & Garden', 'Sports']\n",
    "regions = ['North', 'South', 'East', 'West', 'Central']\n",
    "genders = ['Male', 'Female', 'Other']\n",
    "\n",
    "# Create the dataset\n",
    "customer_data = {\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': ages,\n",
    "    'gender': np.random.choice(genders, n_customers, p=[0.48, 0.48, 0.04]),\n",
    "    'income': income,\n",
    "    'region': np.random.choice(regions, n_customers),\n",
    "    'preferred_category': np.random.choice(categories, n_customers),\n",
    "    'purchase_frequency': purchase_frequency,\n",
    "    'avg_purchase_amount': avg_purchase_amount,\n",
    "    'customer_satisfaction': satisfaction,\n",
    "    'years_as_customer': np.random.exponential(2, n_customers)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(customer_data)\n",
    "\n",
    "# Round numerical columns\n",
    "df['income'] = df['income'].round(0)\n",
    "df['avg_purchase_amount'] = df['avg_purchase_amount'].round(2)\n",
    "df['customer_satisfaction'] = df['customer_satisfaction'].round(1)\n",
    "df['years_as_customer'] = df['years_as_customer'].round(1)\n",
    "\n",
    "# Introduce missing values (realistic scenario)\n",
    "missing_indices = np.random.choice(df.index, size=50, replace=False)\n",
    "df.loc[missing_indices[:25], 'income'] = np.nan\n",
    "df.loc[missing_indices[25:], 'customer_satisfaction'] = np.nan\n",
    "\n",
    "print(f\"Dataset created with {len(df)} customers\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration\n",
    "\n",
    "The first step in any data analysis is understanding what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(\"\\n=== FIRST 5 ROWS ===\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"=== DATA TYPES AND MISSING VALUES ===\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES SUMMARY ===\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': df.isnull().sum(),\n",
    "    'Missing Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "})\n",
    "print(missing_summary[missing_summary['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== NUMERICAL VARIABLES SUMMARY ===\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n=== CATEGORICAL VARIABLES SUMMARY ===\")\n",
    "categorical_cols = ['gender', 'region', 'preferred_category']\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Pandas Operations\n",
    "\n",
    "Let's explore powerful data manipulation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced filtering and selection\n",
    "print(\"=== ADVANCED FILTERING ===\")\n",
    "\n",
    "# High-value customers (top 10% by income)\n",
    "income_threshold = df['income'].quantile(0.9)\n",
    "high_value = df[df['income'] >= income_threshold]\n",
    "print(f\"High-value customers (income >= ${income_threshold:,.0f}): {len(high_value)}\")\n",
    "\n",
    "# Complex conditions\n",
    "young_frequent = df[(df['age'] < 30) & (df['purchase_frequency'] > 10)]\n",
    "print(f\"Young frequent buyers: {len(young_frequent)}\")\n",
    "\n",
    "# Using isin() for multiple values\n",
    "premium_regions = df[df['region'].isin(['North', 'South']) & (df['customer_satisfaction'] >= 4.0)]\n",
    "print(f\"Satisfied customers from North/South: {len(premium_regions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby operations and aggregations\n",
    "print(\"=== GROUPBY ANALYSIS ===\")\n",
    "\n",
    "# Multiple aggregations by region\n",
    "region_stats = df.groupby('region').agg({\n",
    "    'age': ['mean', 'std'],\n",
    "    'income': ['mean', 'median'],\n",
    "    'purchase_frequency': 'mean',\n",
    "    'customer_satisfaction': ['mean', 'count']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Regional statistics:\")\n",
    "print(region_stats)\n",
    "\n",
    "# Cross-tabulation\n",
    "print(\"\\nGender vs Category cross-tabulation:\")\n",
    "crosstab = pd.crosstab(df['gender'], df['preferred_category'], margins=True)\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "print(\"=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "# Create age groups\n",
    "df['age_group'] = pd.cut(df['age'], \n",
    "                        bins=[0, 25, 35, 50, 100], \n",
    "                        labels=['18-25', '26-35', '36-50', '50+'])\n",
    "\n",
    "# Income categories\n",
    "df['income_category'] = pd.cut(df['income'], \n",
    "                              bins=[0, 40000, 70000, 100000, float('inf')], \n",
    "                              labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Calculated fields\n",
    "df['monthly_spending'] = df['purchase_frequency'] * df['avg_purchase_amount']\n",
    "df['spending_per_year'] = df['monthly_spending'] * 12\n",
    "\n",
    "# Customer value score (composite metric)\n",
    "df['customer_value_score'] = (\n",
    "    (df['monthly_spending'] / df['monthly_spending'].max()) * 0.4 +\n",
    "    (df['customer_satisfaction'] / 5) * 0.3 +\n",
    "    (df['years_as_customer'] / df['years_as_customer'].max()) * 0.3\n",
    ") * 100\n",
    "\n",
    "print(\"New features created:\")\n",
    "print(f\"- Age groups: {df['age_group'].value_counts().to_dict()}\")\n",
    "print(f\"- Income categories: {df['income_category'].value_counts().to_dict()}\")\n",
    "print(f\"- Average monthly spending: ${df['monthly_spending'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Missing Data\n",
    "\n",
    "Missing data is common in real datasets. Let's explore different strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data patterns\n",
    "print(\"=== MISSING DATA VISUALIZATION ===\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Missing data heatmap\n",
    "sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis', ax=axes[0])\n",
    "axes[0].set_title('Missing Data Pattern')\n",
    "\n",
    "# Missing data counts\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_counts = missing_counts[missing_counts > 0]\n",
    "axes[1].bar(missing_counts.index, missing_counts.values, color='coral')\n",
    "axes[1].set_title('Missing Data Count by Column')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different missing data strategies\n",
    "print(\"=== MISSING DATA STRATEGIES ===\")\n",
    "\n",
    "# Strategy 1: Simple imputation\n",
    "df_simple = df.copy()\n",
    "df_simple['income'].fillna(df_simple['income'].median(), inplace=True)\n",
    "df_simple['customer_satisfaction'].fillna(df_simple['customer_satisfaction'].mean(), inplace=True)\n",
    "\n",
    "print(f\"Simple imputation - remaining missing values: {df_simple.isnull().sum().sum()}\")\n",
    "\n",
    "# Strategy 2: Group-based imputation\n",
    "df_advanced = df.copy()\n",
    "\n",
    "# Fill income based on age group and region\n",
    "for age_grp in df_advanced['age_group'].unique():\n",
    "    if pd.isna(age_grp):\n",
    "        continue\n",
    "    for region in df_advanced['region'].unique():\n",
    "        mask = (df_advanced['age_group'] == age_grp) & (df_advanced['region'] == region)\n",
    "        group_median = df_advanced.loc[mask, 'income'].median()\n",
    "        \n",
    "        if not pd.isna(group_median):\n",
    "            df_advanced.loc[mask & df_advanced['income'].isna(), 'income'] = group_median\n",
    "\n",
    "# Fill remaining with overall median\n",
    "df_advanced['income'].fillna(df_advanced['income'].median(), inplace=True)\n",
    "df_advanced['customer_satisfaction'].fillna(df_advanced['customer_satisfaction'].mean(), inplace=True)\n",
    "\n",
    "print(f\"Advanced imputation - remaining missing values: {df_advanced.isnull().sum().sum()}\")\n",
    "\n",
    "# Use the advanced imputed dataset\n",
    "df = df_advanced.copy()\n",
    "print(\"Using advanced imputation for further analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection and Treatment\n",
    "\n",
    "Outliers can significantly impact analysis. Let's identify and handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers with box plots\n",
    "print(\"=== OUTLIER VISUALIZATION ===\")\n",
    "\n",
    "numerical_cols = ['age', 'income', 'purchase_frequency', 'avg_purchase_amount', 'customer_satisfaction']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    axes[i].boxplot(df[col].dropna())\n",
    "    axes[i].set_title(f'{col} - Box Plot')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical outlier detection\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "print(\"=== OUTLIER ANALYSIS ===\")\n",
    "for col in ['income', 'purchase_frequency', 'avg_purchase_amount']:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df, col)\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Normal range: [{lower:.2f}, {upper:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comprehensive EDA with Visualizations\n",
    "\n",
    "Now let's create comprehensive visualizations to understand our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis\n",
    "print(\"=== DISTRIBUTION ANALYSIS ===\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Age distribution\n",
    "axes[0, 0].hist(df['age'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Age Distribution')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Income distribution\n",
    "axes[0, 1].hist(df['income'], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_title('Income Distribution')\n",
    "axes[0, 1].set_xlabel('Income ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Purchase frequency\n",
    "axes[0, 2].hist(df['purchase_frequency'], bins=20, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[0, 2].set_title('Purchase Frequency Distribution')\n",
    "axes[0, 2].set_xlabel('Purchases per Month')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Customer satisfaction\n",
    "axes[1, 0].hist(df['customer_satisfaction'], bins=20, alpha=0.7, color='gold', edgecolor='black')\n",
    "axes[1, 0].set_title('Customer Satisfaction Distribution')\n",
    "axes[1, 0].set_xlabel('Satisfaction Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Monthly spending\n",
    "axes[1, 1].hist(df['monthly_spending'], bins=30, alpha=0.7, color='purple', edgecolor='black')\n",
    "axes[1, 1].set_title('Monthly Spending Distribution')\n",
    "axes[1, 1].set_xlabel('Monthly Spending ($)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Customer value score\n",
    "axes[1, 2].hist(df['customer_value_score'], bins=30, alpha=0.7, color='pink', edgecolor='black')\n",
    "axes[1, 2].set_title('Customer Value Score Distribution')\n",
    "axes[1, 2].set_xlabel('Value Score')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical analysis\n",
    "print(\"=== CATEGORICAL ANALYSIS ===\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = df['gender'].value_counts()\n",
    "axes[0, 0].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0, 0].set_title('Gender Distribution')\n",
    "\n",
    "# Region distribution\n",
    "region_counts = df['region'].value_counts()\n",
    "axes[0, 1].bar(region_counts.index, region_counts.values, color='lightblue')\n",
    "axes[0, 1].set_title('Customer Distribution by Region')\n",
    "axes[0, 1].set_xlabel('Region')\n",
    "axes[0, 1].set_ylabel('Number of Customers')\n",
    "\n",
    "# Preferred category\n",
    "category_counts = df['preferred_category'].value_counts()\n",
    "axes[1, 0].bar(category_counts.index, category_counts.values, color='lightcoral')\n",
    "axes[1, 0].set_title('Preferred Category Distribution')\n",
    "axes[1, 0].set_xlabel('Category')\n",
    "axes[1, 0].set_ylabel('Number of Customers')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Age group distribution\n",
    "age_group_counts = df['age_group'].value_counts()\n",
    "axes[1, 1].bar(age_group_counts.index, age_group_counts.values, color='gold')\n",
    "axes[1, 1].set_title('Age Group Distribution')\n",
    "axes[1, 1].set_xlabel('Age Group')\n",
    "axes[1, 1].set_ylabel('Number of Customers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"=== CORRELATION ANALYSIS ===\")\n",
    "\n",
    "# Select numerical columns for correlation\n",
    "numerical_cols = ['age', 'income', 'purchase_frequency', 'avg_purchase_amount', \n",
    "                 'customer_satisfaction', 'years_as_customer', 'monthly_spending', 'customer_value_score']\n",
    "\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print strong correlations\n",
    "print(\"\\nStrong correlations (|r| > 0.5):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.5:\n",
    "            print(f\"{correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practice Exercises\n",
    "\n",
    "Now it's your turn to practice what you've learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Advanced Filtering\n",
    "Create filters to find:\n",
    "1. Customers aged 25-40 with high satisfaction (>4.0)\n",
    "2. Electronics customers with monthly spending > $500\n",
    "3. Female customers from East or West regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Exercise 1 solutions\n",
    "\n",
    "# 1. Customers aged 25-40 with high satisfaction\n",
    "satisfied_middle_age = df[(df['age'] >= 25) & (df['age'] <= 40) & (df['customer_satisfaction'] > 4.0)]\n",
    "print(f\"Satisfied middle-aged customers: {len(satisfied_middle_age)}\")\n",
    "\n",
    "# 2. Electronics customers with high monthly spending\n",
    "high_spending_electronics = df[(df['preferred_category'] == 'Electronics') & (df['monthly_spending'] > 500)]\n",
    "print(f\"High-spending electronics customers: {len(high_spending_electronics)}\")\n",
    "\n",
    "# 3. Female customers from East or West\n",
    "female_east_west = df[(df['gender'] == 'Female') & (df['region'].isin(['East', 'West']))]\n",
    "print(f\"Female customers from East/West: {len(female_east_west)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Groupby Analysis\n",
    "Perform the following analyses:\n",
    "1. Average income by age group and gender\n",
    "2. Total monthly spending by region and preferred category\n",
    "3. Customer satisfaction statistics by income category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Exercise 2 solutions\n",
    "\n",
    "# 1. Average income by age group and gender\n",
    "income_by_age_gender = df.groupby(['age_group', 'gender'])['income'].mean().round(2)\n",
    "print(\"Average income by age group and gender:\")\n",
    "print(income_by_age_gender)\n",
    "\n",
    "# 2. Total monthly spending by region and category\n",
    "spending_by_region_category = df.groupby(['region', 'preferred_category'])['monthly_spending'].sum().round(2)\n",
    "print(\"\\nTotal monthly spending by region and category:\")\n",
    "print(spending_by_region_category)\n",
    "\n",
    "# 3. Customer satisfaction by income category\n",
    "satisfaction_by_income = df.groupby('income_category')['customer_satisfaction'].agg(['mean', 'std', 'count']).round(2)\n",
    "print(\"\\nCustomer satisfaction by income category:\")\n",
    "print(satisfaction_by_income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Data Visualization Challenge\n",
    "Create visualizations to answer these questions:\n",
    "1. How does monthly spending vary across different age groups?\n",
    "2. Which regions have the highest customer satisfaction?\n",
    "3. Is there a relationship between income and years as customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Exercise 3 solutions\n",
    "\n",
    "# 1. Monthly spending by age group\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.boxplot(column='monthly_spending', by='age_group', ax=plt.gca())\n",
    "plt.title('Monthly Spending Distribution by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Monthly Spending ($)')\n",
    "plt.show()\n",
    "\n",
    "# 2. Customer satisfaction by region\n",
    "plt.figure(figsize=(10, 6))\n",
    "satisfaction_by_region = df.groupby('region')['customer_satisfaction'].mean().sort_values(ascending=False)\n",
    "satisfaction_by_region.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Customer Satisfaction by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Average Satisfaction Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 3. Income vs years as customer\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['years_as_customer'], df['income'], alpha=0.6)\n",
    "plt.xlabel('Years as Customer')\n",
    "plt.ylabel('Income ($)')\n",
    "plt.title('Income vs Years as Customer')\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = df['years_as_customer'].corr(df['income'])\n",
    "print(f\"Correlation between years as customer and income: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've covered essential data manipulation and exploratory data analysis techniques:\n",
    "\n",
    "### Key Skills Learned:\n",
    "1. **Advanced Pandas Operations**: Complex filtering, groupby operations, and feature engineering\n",
    "2. **Missing Data Handling**: Multiple imputation strategies and visualization techniques\n",
    "3. **Outlier Detection**: Statistical methods using IQR and visualization approaches\n",
    "4. **Comprehensive EDA**: Distribution analysis, correlation analysis, and categorical data exploration\n",
    "5. **Data Visualization**: Using Matplotlib and Seaborn for meaningful insights\n",
    "\n",
    "### Best Practices:\n",
    "- Always start with basic data exploration before diving into analysis\n",
    "- Handle missing data thoughtfully with appropriate strategies\n",
    "- Visualize data distributions and relationships to gain insights\n",
    "- Document your findings and reasoning throughout the analysis\n",
    "- Validate assumptions and check for data quality issues\n",
    "\n",
    "These skills form the foundation for more advanced machine learning techniques we'll explore in upcoming weeks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}
