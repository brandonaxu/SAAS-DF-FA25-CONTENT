{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: Computer Vision & Image Processing\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "- Understand the fundamentals of digital images and computer vision\n",
    "- Perform basic image processing operations \n",
    "- Apply traditional computer vision techniques\n",
    "- Build image classification models using neural networks\n",
    "- Understand convolutional neural networks (CNNs)\n",
    "- Work with real image datasets\n",
    "- Apply computer vision to practical problems\n",
    "- Understand modern computer vision applications\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Computer Vision\n",
    "\n",
    "Computer Vision is a field of AI that enables computers to interpret and understand visual information from the world. Applications include:\n",
    "\n",
    "- **Autonomous Vehicles**: Object detection, lane recognition\n",
    "- **Healthcare**: Medical image analysis, disease diagnosis\n",
    "- **Security**: Face recognition, surveillance systems\n",
    "- **Retail**: Product recognition, visual search\n",
    "- **Social Media**: Photo tagging, content moderation\n",
    "- **Manufacturing**: Quality control, defect detection\n",
    "- **Agriculture**: Crop monitoring, pest detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Computer vision libraries\n",
    "try:\n",
    "    import cv2\n",
    "    CV2_AVAILABLE = True\n",
    "    print(\"OpenCV available for advanced image processing!\")\n",
    "except ImportError:\n",
    "    print(\"OpenCV not available. Install with: pip install opencv-python\")\n",
    "    CV2_AVAILABLE = False\n",
    "\n",
    "# Deep learning libraries (optional)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    TF_AVAILABLE = True\n",
    "    print(f\"TensorFlow available for deep learning! Version: {tf.__version__}\")\n",
    "    tf.random.set_seed(42)\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. We'll use scikit-learn for image classification.\")\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "# Built-in datasets\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")\n",
    "print(\"Ready to explore Computer Vision! 👁️🤖\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Digital Images\n",
    "\n",
    "### 2.1 Image Representation and Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== UNDERSTANDING DIGITAL IMAGES ===\\n\")\n",
    "\n",
    "# Load the digits dataset for demonstration\n",
    "digits = load_digits()\n",
    "print(f\"Digits dataset loaded:\")\n",
    "print(f\"• Images: {digits.data.shape[0]}\")\n",
    "print(f\"• Image size: {digits.images.shape[1]}x{digits.images.shape[2]} pixels\")\n",
    "print(f\"• Classes: {len(np.unique(digits.target))} (digits 0-9)\")\n",
    "print(f\"• Data shape: {digits.data.shape}\")\n",
    "\n",
    "# Visualize some sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "for i in range(10):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    \n",
    "    # Display the image\n",
    "    axes[row, col].imshow(digits.images[i], cmap='gray')\n",
    "    axes[row, col].set_title(f'Digit: {digits.target[i]}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Handwritten Digits (8x8 pixels)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Explore image properties\n",
    "print(f\"\\nImage Analysis:\")\n",
    "sample_image = digits.images[0]\n",
    "print(f\"• Sample image shape: {sample_image.shape}\")\n",
    "print(f\"• Data type: {sample_image.dtype}\")\n",
    "print(f\"• Pixel value range: {sample_image.min():.1f} to {sample_image.max():.1f}\")\n",
    "print(f\"• Mean pixel value: {sample_image.mean():.2f}\")\n",
    "\n",
    "# Show pixel values for a small section\n",
    "print(f\"\\nPixel values (top-left 4x4 corner):\")\n",
    "print(sample_image[:4, :4])\n",
    "\n",
    "# Demonstrate how images are flattened for machine learning\n",
    "print(f\"\\nFlattened representation:\")\n",
    "print(f\"• Original shape: {sample_image.shape}\")\n",
    "print(f\"• Flattened shape: {digits.data[0].shape}\")\n",
    "print(f\"• First 10 pixel values: {digits.data[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Image Processing\n",
    "\n",
    "### 3.1 Image Transformations and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== BASIC IMAGE PROCESSING ===\\n\")\n",
    "\n",
    "# Select a sample image for processing\n",
    "sample_idx = 100\n",
    "original_image = digits.images[sample_idx]\n",
    "print(f\"Processing digit: {digits.target[sample_idx]}\")\n",
    "\n",
    "# Define some basic image processing functions\n",
    "def apply_gaussian_blur(image, sigma=1.0):\n",
    "    \"\"\"Apply Gaussian blur to an image\"\"\"\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    return gaussian_filter(image, sigma=sigma)\n",
    "\n",
    "def apply_edge_detection(image):\n",
    "    \"\"\"Simple edge detection using gradient\"\"\"\n",
    "    from scipy.ndimage import sobel\n",
    "    # Sobel edge detection\n",
    "    edge_x = sobel(image, axis=0)\n",
    "    edge_y = sobel(image, axis=1)\n",
    "    return np.sqrt(edge_x**2 + edge_y**2)\n",
    "\n",
    "def adjust_contrast(image, factor=1.5):\n",
    "    \"\"\"Adjust image contrast\"\"\"\n",
    "    mean_val = image.mean()\n",
    "    return np.clip((image - mean_val) * factor + mean_val, 0, 16)\n",
    "\n",
    "def apply_threshold(image, threshold=8.0):\n",
    "    \"\"\"Apply binary thresholding\"\"\"\n",
    "    return (image > threshold).astype(float) * 16\n",
    "\n",
    "# Apply different transformations\n",
    "transformations = {\n",
    "    'Original': original_image,\n",
    "    'Gaussian Blur': apply_gaussian_blur(original_image, sigma=0.8),\n",
    "    'Edge Detection': apply_edge_detection(original_image),\n",
    "    'High Contrast': adjust_contrast(original_image, factor=2.0),\n",
    "    'Binary Threshold': apply_threshold(original_image, threshold=6.0),\n",
    "    'Inverted': 16 - original_image\n",
    "}\n",
    "\n",
    "# Visualize transformations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, image) in enumerate(transformations.items()):\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].set_title(f'{name}')\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Add some statistics\n",
    "    axes[i].text(0.02, 0.98, f'Min: {image.min():.1f}\\nMax: {image.max():.1f}', \n",
    "                transform=axes[i].transAxes, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.suptitle(f'Image Processing Techniques - Digit {digits.target[sample_idx]}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Key Concepts:\")\n",
    "print(f\"• Gaussian Blur: Reduces noise and detail\")\n",
    "print(f\"• Edge Detection: Highlights boundaries and features\")\n",
    "print(f\"• Contrast Adjustment: Enhances visual differences\")\n",
    "print(f\"• Thresholding: Converts to binary (black/white)\")\n",
    "print(f\"• Inversion: Flips pixel intensities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Traditional Machine Learning for Images\n",
    "\n",
    "### 4.1 Feature Extraction and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TRADITIONAL ML FOR IMAGE CLASSIFICATION ===\\n\")\n",
    "\n",
    "# Prepare the data\n",
    "X = digits.data  # Flattened pixel values\n",
    "y = digits.target  # Digit labels\n",
    "\n",
    "print(f\"Dataset information:\")\n",
    "print(f\"• Total images: {X.shape[0]}\")\n",
    "print(f\"• Features per image: {X.shape[1]} (pixels)\")\n",
    "print(f\"• Classes: {len(np.unique(y))}\")\n",
    "print(f\"• Class distribution: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"• Training samples: {X_train.shape[0]}\")\n",
    "print(f\"• Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Train and compare different models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"\\nTraining and evaluating models:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:20}: {accuracy:.3f}\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nModel Comparison:\")\n",
    "print(results_df.round(3))\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = results_df['Accuracy'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
    "best_accuracy = results_df.loc[best_model_idx, 'Accuracy']\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model_name} ({best_accuracy:.3f} accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction for Images\n",
    "\n",
    "### 5.1 Principal Component Analysis (PCA) for Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PCA FOR IMAGE ANALYSIS ===\\n\")\n",
    "\n",
    "# Apply PCA to the digit images\n",
    "pca = PCA(n_components=32, random_state=42)  # Reduce from 64 to 32 dimensions\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"PCA Results:\")\n",
    "print(f\"• Original dimensions: {X_train.shape[1]}\")\n",
    "print(f\"• Reduced dimensions: {X_train_pca.shape[1]}\")\n",
    "print(f\"• Variance explained: {pca.explained_variance_ratio_.sum():.3f} ({pca.explained_variance_ratio_.sum()*100:.1f}%)\")\n",
    "print(f\"• Dimensionality reduction: {X_train.shape[1]/X_train_pca.shape[1]:.1f}x\")\n",
    "\n",
    "# Visualize the principal components (eigendigits)\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "for i in range(32):\n",
    "    row = i // 8\n",
    "    col = i % 8\n",
    "    \n",
    "    # Reshape component back to image format\n",
    "    component_image = pca.components_[i].reshape(8, 8)\n",
    "    \n",
    "    axes[row, col].imshow(component_image, cmap='coolwarm')\n",
    "    axes[row, col].set_title(f'PC{i+1}\\n({pca.explained_variance_ratio_[i]:.1%})', fontsize=8)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle('Principal Components (Eigendigits)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test classification performance with PCA\n",
    "rf_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_pca.fit(X_train_pca, y_train)\n",
    "pred_pca = rf_pca.predict(X_test_pca)\n",
    "acc_pca = accuracy_score(y_test, pred_pca)\n",
    "\n",
    "print(f\"\\nClassification with PCA features:\")\n",
    "print(f\"• Accuracy: {acc_pca:.3f}\")\n",
    "print(f\"• Feature reduction: {X_train.shape[1]} → {X_train_pca.shape[1]} dimensions\")\n",
    "print(f\"• Maintains good performance with 50% fewer features\")\n",
    "\n",
    "# Show reconstruction examples\n",
    "print(f\"\\nImage Reconstruction with PCA:\")\n",
    "\n",
    "# Reconstruct some test images\n",
    "n_samples = 5\n",
    "sample_indices = [0, 50, 100, 150, 200]\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(15, 6))\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Original image\n",
    "    original = X_test[idx].reshape(8, 8)\n",
    "    axes[0, i].imshow(original, cmap='gray')\n",
    "    axes[0, i].set_title(f'Original\\nDigit: {y_test[idx]}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstructed image\n",
    "    pca_coords = X_test_pca[idx]\n",
    "    reconstructed = pca.inverse_transform(pca_coords.reshape(1, -1))\n",
    "    reconstructed = reconstructed.reshape(8, 8)\n",
    "    \n",
    "    axes[1, i].imshow(reconstructed, cmap='gray')\n",
    "    axes[1, i].set_title('PCA\\nReconstructed')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Original vs PCA Reconstructed Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPCA Insights:\")\n",
    "print(f\"• First few components capture most important image features\")\n",
    "print(f\"• Reconstruction preserves essential digit characteristics\")\n",
    "print(f\"• Significant dimensionality reduction with minimal information loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modern Computer Vision Concepts\n",
    "\n",
    "### 6.1 Understanding CNNs and Deep Learning for Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MODERN COMPUTER VISION CONCEPTS ===\\n\")\n",
    "\n",
    "if TF_AVAILABLE:\n",
    "    print(\"Exploring CNNs with TensorFlow...\")\n",
    "    \n",
    "    # Prepare data for CNN (needs to be reshaped)\n",
    "    X_train_cnn = X_train.reshape(-1, 8, 8, 1).astype('float32') / 16.0  # Normalize\n",
    "    X_test_cnn = X_test.reshape(-1, 8, 8, 1).astype('float32') / 16.0\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    y_train_cnn = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test_cnn = keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    print(f\"CNN Data shapes:\")\n",
    "    print(f\"• X_train: {X_train_cnn.shape} (samples, height, width, channels)\")\n",
    "    print(f\"• y_train: {y_train_cnn.shape} (samples, classes)\")\n",
    "    \n",
    "    # Build a simple CNN\n",
    "    model = keras.Sequential([\n",
    "        # Convolutional layers\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=(8, 8, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCNN Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train the CNN\n",
    "    print(f\"\\nTraining CNN...\")\n",
    "    history = model.fit(\n",
    "        X_train_cnn, y_train_cnn,\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate CNN\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "    print(f\"\\nCNN Results:\")\n",
    "    print(f\"• Test accuracy: {test_accuracy:.3f}\")\n",
    "    print(f\"• Comparison with best traditional ML: {test_accuracy:.3f} vs {best_accuracy:.3f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"TensorFlow not available - explaining CNN concepts:\")\n",
    "    \n",
    "print(f\"\\nKey CNN Concepts:\")\n",
    "print(f\"=\" * 30)\n",
    "concepts = {\n",
    "    \"Convolutional Layers\": {\n",
    "        \"purpose\": \"Detect local features using filters/kernels\",\n",
    "        \"advantage\": \"Preserve spatial relationships in images\"\n",
    "    },\n",
    "    \"Pooling Layers\": {\n",
    "        \"purpose\": \"Reduce spatial dimensions and computational cost\",\n",
    "        \"advantage\": \"Provide translation invariance\"\n",
    "    },\n",
    "    \"Feature Maps\": {\n",
    "        \"purpose\": \"Represent detected features at different layers\",\n",
    "        \"advantage\": \"Build hierarchical feature representations\"\n",
    "    },\n",
    "    \"Parameter Sharing\": {\n",
    "        \"purpose\": \"Use same filters across entire image\",\n",
    "        \"advantage\": \"Reduce parameters and improve generalization\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for concept, details in concepts.items():\n",
    "    print(f\"\\n{concept}:\")\n",
    "    print(f\"  Purpose: {details['purpose']}\")\n",
    "    print(f\"  Advantage: {details['advantage']}\")\n",
    "\n",
    "print(f\"\\nWhy CNNs Excel at Computer Vision:\")\n",
    "print(f\"• Automatic feature learning (no manual feature engineering)\")\n",
    "print(f\"• Hierarchical feature detection (edges → shapes → objects)\")\n",
    "print(f\"• Translation invariance (detect features anywhere in image)\")\n",
    "print(f\"• Efficient parameter sharing reduces overfitting\")\n",
    "print(f\"• Can handle variable input sizes and complex patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Practice Exercises\n",
    "\n",
    "Now it's your turn to practice what you've learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Image Processing Exploration\n",
    "\n",
    "Experiment with different image processing techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Try different threshold values, blur parameters, or create your own filters\n",
    "\n",
    "# Sample solution:\n",
    "def create_custom_filter(image, filter_type='sharpen'):\n",
    "    from scipy.ndimage import convolve\n",
    "    \n",
    "    if filter_type == 'sharpen':\n",
    "        kernel = np.array([[-1, -1, -1],\n",
    "                          [-1,  9, -1],\n",
    "                          [-1, -1, -1]])\n",
    "    elif filter_type == 'emboss':\n",
    "        kernel = np.array([[-2, -1,  0],\n",
    "                          [-1,  1,  1],\n",
    "                          [ 0,  1,  2]])\n",
    "    else:\n",
    "        kernel = np.array([[0, -1,  0],\n",
    "                          [-1, 5, -1],\n",
    "                          [0, -1,  0]])\n",
    "    \n",
    "    return convolve(image, kernel)\n",
    "\n",
    "# Test custom filters\n",
    "test_image = digits.images[50]\n",
    "sharpened = create_custom_filter(test_image, 'sharpen')\n",
    "embossed = create_custom_filter(test_image, 'emboss')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(test_image, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(sharpened, cmap='gray')\n",
    "axes[1].set_title('Sharpened')\n",
    "axes[2].imshow(embossed, cmap='gray')\n",
    "axes[2].set_title('Embossed')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Feature Engineering for Images\n",
    "\n",
    "Create your own image features and test their effectiveness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Extract features like symmetry, density, or geometric properties\n",
    "\n",
    "# Sample solution:\n",
    "def extract_advanced_features(images, original_shape=(8, 8)):\n",
    "    \"\"\"Extract advanced image features\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for img_flat in images:\n",
    "        img_2d = img_flat.reshape(original_shape)\n",
    "        \n",
    "        feature_vector = [\n",
    "            # Intensity features\n",
    "            img_flat.mean(),\n",
    "            img_flat.std(),\n",
    "            img_flat.max() - img_flat.min(),\n",
    "            \n",
    "            # Geometric features\n",
    "            np.sum(img_2d > img_2d.mean()) / img_2d.size,  # Fill ratio\n",
    "            \n",
    "            # Edge features\n",
    "            apply_edge_detection(img_2d).sum(),\n",
    "            \n",
    "            # Symmetry features\n",
    "            np.corrcoef(img_2d.flatten(), np.fliplr(img_2d).flatten())[0,1],  # Horizontal symmetry\n",
    "            np.corrcoef(img_2d.flatten(), np.flipud(img_2d).flatten())[0,1],  # Vertical symmetry\n",
    "        ]\n",
    "        \n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Test advanced features\n",
    "X_train_advanced = extract_advanced_features(X_train)\n",
    "X_test_advanced = extract_advanced_features(X_test)\n",
    "\n",
    "# Train classifier with advanced features\n",
    "rf_advanced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_advanced.fit(X_train_advanced, y_train)\n",
    "pred_advanced = rf_advanced.predict(X_test_advanced)\n",
    "acc_advanced = accuracy_score(y_test, pred_advanced)\n",
    "\n",
    "print(f\"Advanced features accuracy: {acc_advanced:.3f}\")\n",
    "print(f\"Feature importance: {rf_advanced.feature_importances_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored Computer Vision and Image Processing:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "✅ **Digital Images**: Understanding pixel representations and image properties  \n",
    "✅ **Image Processing**: Filters, transformations, and enhancement techniques  \n",
    "✅ **Traditional ML**: Feature extraction and classification for images  \n",
    "✅ **Dimensionality Reduction**: PCA for image compression and analysis  \n",
    "✅ **Modern Computer Vision**: CNN concepts and deep learning approaches  \n",
    "\n",
    "### Key Takeaways:\n",
    "- Images are numerical arrays that can be processed mathematically\n",
    "- Traditional image processing uses filters and transformations\n",
    "- Machine learning can classify images using pixel features\n",
    "- PCA effectively reduces image dimensionality while preserving information\n",
    "- CNNs revolutionized computer vision through automatic feature learning\n",
    "- Different approaches work better for different types of image problems\n",
    "\n",
    "### Real-World Applications:\n",
    "- **Medical Imaging**: Disease diagnosis from X-rays, MRIs\n",
    "- **Autonomous Vehicles**: Object detection and navigation\n",
    "- **Security Systems**: Face recognition and surveillance\n",
    "- **Quality Control**: Defect detection in manufacturing\n",
    "- **Social Media**: Photo tagging and content moderation\n",
    "\n",
    "### Course Completion:\n",
    "🎉 **Congratulations! You've completed the 10-week Data Science Course!** 🎉\n",
    "\n",
    "You now have a comprehensive understanding of:\n",
    "- Python programming for data science\n",
    "- Data manipulation and visualization\n",
    "- Statistical analysis and hypothesis testing\n",
    "- Machine learning algorithms (supervised and unsupervised)\n",
    "- Neural networks and deep learning\n",
    "- Natural language processing\n",
    "- Computer vision and image processing\n",
    "\n",
    "### Homework Assignment\n",
    "1. Complete all practice exercises above\n",
    "2. Experiment with different image processing techniques\n",
    "3. Compare traditional ML vs deep learning approaches\n",
    "4. Build a complete image classification project\n",
    "\n",
    "### Additional Resources\n",
    "- [OpenCV Documentation](https://docs.opencv.org/)\n",
    "- [Computer Vision: Algorithms and Applications](http://szeliski.org/Book/)\n",
    "- [PyImageSearch Tutorials](https://pyimagesearch.com/)\n",
    "- [TensorFlow Computer Vision Tutorials](https://www.tensorflow.org/tutorials/images)\n",
    "\n",
    "**You are now ready to tackle real-world data science challenges!** 🚀👁️🤖"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
